이벤트 뷰어 
  eventvwr.msc

// Elastic Stack 설치 7.10.1,   8.13.1 (최신 버젼) 

   https://esbook.kimjmin.net/		<== 한글 버젼 공부 할 수 있는 사이트 
  
   https://www.elastic.co/    <== 공식 사이트 
   https://www.elastic.co/kr/downloads   <== 모든 제품, 모든 버젼 다운로드 

   https://www.elastic.co/kr/support/matrix	<== 모든 버젼의 설치 가능한 OS 버젼을 확인 , 매트릭스 
   

	Elasticsearch	: 9200 포트사용
	Kibana		: 5601 포트사용
	
  1. Windows 10 		<== 테스트/실습 ( 7.10 ) 
	파일명 :  elasticsearch-7.10.1-windows-x86_64.zip   ==> elasticsearch-7.zip
		 kibana-7.10.1-windows-x86_64.zip	   ==> kibana-7.zip

     명령프롬프트 (관리자 권한으로 실행) 
     - elasticsearch-7 설치 ,    9200 포트 사용 
	// 압축 풀린 폴더 이동후 
	C:\elasticsearch7>.\bin\elasticsearch.bat		<== 창은 종료하면 안됨

	// 명령 프롬프트 창을 하나더 띄운 다음 실행 : 
	C:\elasticsearch7>curl -X GET "localhost:9200/?pretty"

=========아래 내용 잘 출력 되면 정상 작동 ========================
{
  "name" : "DESKTOP-VI3SD85",
  "cluster_name" : "elasticsearch",
  "cluster_uuid" : "F5UaffBBQIWbeQBurkEOcw",
  "version" : {
    "number" : "7.10.1",
    "build_flavor" : "default",
    "build_type" : "zip",
    "build_hash" : "1c34507e66d7db1211f66f3513706fdf548736aa",
    "build_date" : "2020-12-05T01:00:33.671820Z",
    "build_snapshot" : false,
    "lucene_version" : "8.7.0",
    "minimum_wire_compatibility_version" : "6.8.0",
    "minimum_index_compatibility_version" : "6.0.0-beta1"
  },
  "tagline" : "You Know, for Search"
}
==========================================================================	
	
	//Kibana 실행   <== 
	C:\kibana7>.\bin\kibana.bat

	   // 웹브라우져 : http://localhost:5601	<== 키바나 관리툴 접속 

	// 라이센스 업데이트 : 30일 동안 무료로 사용할수 있도록 적용 
	Management => Stack Management => License management => 30 Days Tiral (클릭) 

	//Elastic 에서 제공 해주는 Sample Data Import 
	Home => Try our sample data (클릭) 

=============================================================================================================================
  2. Linux (Ubuntu 22.04)   		<== 운영 환경   ( ELK-Stack 8.13.1 )
	https://www.elastic.co/guide/en/elasticsearch/reference/8.13/deb.html	//공식 사이트 : Debian 계열 Linux : Debian, Ubuntu, Kali .... 
		apt, apt-get 을 사용 해서 설치 

     ELK-Stack1         192.168.15.40	매핑포트(포트포워딩) : 22040
     ELK-Stack3	       192.168.15.60	매핑포트(포트포워딩) : 22040

     //컴퓨터 이름변경 : sudo cat /etc/hostname 			sudo vi /etc/hostname
     // IP 변경        : sudo cat /etc/netplan/00-installer-config.yaml	sudo vi /etc/netplan/00-installer-config.yaml
     // 리부팅         : sudo reboot       or    sudo init 6



// ElasticSearch 설치 
     2-1 Import the Elasticsearch PGP Key : 설치를 위한 키등록 
	wget -qO - https://artifacts.elastic.co/GPG-KEY-elasticsearch | sudo gpg --dearmor -o /usr/share/keyrings/elasticsearch-keyring.gpg

     2-2 Installing from the APT repository :  Elastic 가 저장된 레파지토리 등록
	apt-get update
	sudo apt-get install apt-transport-https
	echo "deb [signed-by=/usr/share/keyrings/elasticsearch-keyring.gpg] https://artifacts.elastic.co/packages/8.x/apt stable main" | sudo tee /etc/apt/sources.list.d/elastic-8.x.list

     2-3 Elastic Search 설치 
	sudo apt-get install elasticsearch

        <중요> 출력 내용 확인 : elastic  <== ID,  password 적어두어야함. 

--------------------------- Security autoconfiguration information ------------------------------

Authentication and authorization are enabled.
TLS for the transport and HTTP layers is enabled and configured.

The generated password for the elastic built-in superuser is : <<암호화된 패스워드>>

If this node should join an existing cluster, you can reconfigure this with
'/usr/share/elasticsearch/bin/elasticsearch-reconfigure-node --enrollment-token <token-here>'
after creating an enrollment token on your existing cluster.

You can complete the following actions at any time:

Reset the password of the elastic built-in superuser with
'/usr/share/elasticsearch/bin/elasticsearch-reset-password -u elastic'.

Generate an enrollment token for Kibana instances with
 '/usr/share/elasticsearch/bin/elasticsearch-create-enrollment-token -s kibana'.

Generate an enrollment token for Elasticsearch nodes with
'/usr/share/elasticsearch/bin/elasticsearch-create-enrollment-token -s node'.

-------------------------------------------------------------------------------------------------

     2-4. 설치 완료후 서비스 리로드, 시스템 부팅시 자동으로 서비스 시작,  서비스 시작 
	sudo systemctl daemon-reload
 	sudo systemctl enable elasticsearch	//시스템 부팅시 자동으로 서비스 시작
	sudo systemctl start elasticsearch	// 서비스 시작 
	sudo systemctl status elasticsearch	// 서비스 상태 확인 

// 키바나 설치 
	https://www.elastic.co/guide/en/kibana/current/deb.html

    
    ======2-5 ~ 2-7 까지 같은 내용 : ElasticSearch 와 다른 시스템에 설치할경우에만 실행 ======================
     
     2-5. Import the Elastic PGP key : 
	wget -qO - https://artifacts.elastic.co/GPG-KEY-elasticsearch | sudo gpg --dearmor -o /usr/share/keyrings/elasticsearch-keyring.gpg

     2-6. 
	sudo apt-get update
	sudo apt-get install apt-transport-https

      2-7. 
	echo "deb [signed-by=/usr/share/keyrings/elasticsearch-keyring.gpg] https://artifacts.elastic.co/packages/8.x/apt stable main" | sudo tee /etc/apt/sources.list.d/elastic-8.x.list

      ==========================================================================================================

      2-8 키바나 설치 
	sudo apt-get install kibana

      2-9 Start Elasticsearch and generate an enrollment token for Kibana   : 키바나 작동을 위한  Elasticsearch token 생성 
	/usr/share/elasticsearch/bin/elasticsearch-create-enrollment-token -s kibana
	<출력된 토큰 복사> 

      2-10 키바나 서비스 시작, 자동 시작 
	sudo systemctl daemon-reload
 	sudo systemctl enable kibana		//시스템 부팅시 자동으로 서비스 시작
	sudo systemctl start kibana		// 서비스 시작 
	sudo systemctl status kibana		// 서비스 상태 확인 
		http://localhost:5601/?code=307848

      
      2-11 원격에서 접근 허용 : 
	vi /etc/kibana/kibana.yml
		 11  server.host: "192.168.15.40"     <=== 수정  11  #server.host: "localhost"
	sudo systemctl restart kibana

       2-12 키바나 구성 : windev 에서 웹브라우져 에서 확인 
	https://192.168.15.40:5601/?code=307848
		http://localhost:5601/?code=307848

        // 2-9번에서 출력한 enrollment token for Kibana 입력 
	// 확인 코드 입력 
	sudo systemctl status  	//제일 아랫라인에서 확인 
	
	로그인 ID : elastic 

        2-13 라이센스 등록 : 30일동안 무료 사용 
		Management => Stack Management  ==> License management => 30Days 

        2-14 elastic 계정의 패스워드 변경 : Pa$$w0rd
		Management => Stack Management ==> Security => Users





==============================================================================================================================
  3. Linux Docker (Ubuntu 22.04)		<== 운영 환경   ( 8.13.1 ) 
     ELK-Stack2(Docker)   192.168.15.50	매핑포트(포트포워딩) : 22050

     //컴퓨터 이름변경 : sudo cat /etc/hostname 			sudo vi /etc/hostname
     // IP 변경        : sudo cat /etc/netplan/00-installer-config.yaml	sudo vi /etc/netplan/00-installer-config.yaml
     // 리부팅         : sudo reboot       or    sudo init 6


//도커 설치 
    //도커 설치 
    
# Add Docker's official GPG key:    <== 도커를 설치하기위한 인증키 셋팅  
  sudo apt-get update
  sudo apt-get install ca-certificates curl
  sudo install -m 0755 -d /etc/apt/keyrings
  sudo curl -fsSL https://download.docker.com/linux/ubuntu/gpg -o /etc/apt/keyrings/docker.asc
  sudo chmod a+r /etc/apt/keyrings/docker.asc

# Add the repository to Apt sources:   < == 도커를 다운받을 레파지토리 업데이트 

echo \
  "deb [arch=$(dpkg --print-architecture) signed-by=/etc/apt/keyrings/docker.asc] https://download.docker.com/linux/ubuntu \
  $(. /etc/os-release && echo "$VERSION_CODENAME") stable" | \
  sudo tee /etc/apt/sources.list.d/docker.list > /dev/null

sudo apt-get update


// 도커 설치 
	sudo apt-get install docker-ce docker-ce-cli containerd.io docker-buildx-plugin docker-compose-plugin

	// 작동 확인
	docker -v 
	sudo docker run hello-world
	docker                        // 명령어 메뉴얼 잘 출력 
	sudo systemctl status docker 

	// 설치 완료후 작업 : 특정 사용자 계정에게 도커를 사용할 수 있도록 권한 부여 

	sudo groupadd docker
	sudo usermod -aG docker $USER

	// Security Issues 
	sudo chmod 666 /var/run/docker.sock 				or sudo chown root:docker /var/run/docker.sock

	// 확인 
	sudo cat /etc/group 
   	// docker 그룹에 user1   계정이 포함. 


//엘라스틱 서치(ElasticSearch 8.13), 키바나(Kibana 8.13)   설치 , 두개의 컨테이너가 동일한 도커 네트워크에 있어야 통신   
	- 도커 컴포즈를 사용해서 여러개의 컨테이너를 작동 할때는 동일한 도커 네트워크에 있음. 

	// 컨테이너와 컨테이너 사이에 통신이 가능 하도록 할려면 동일한 도커 네트워크에 존재해야 함. 
	// ElasticSearch 컨테이너 작동 
	docker network create elastic
	docker pull docker.elastic.co/elasticsearch/elasticsearch:8.13.1
	docker run --name es01 --net elastic -p 9200:9200 -p 9300:9300 -e "discovery.type=single-node" -t docker.elastic.co/elasticsearch/elasticsearch:8.13.1

	// 환경변수 ELASTIC_PASSWORD 에 elastic 계정의 암호 저장 
	export ELASTIC_PASSWORD="your_password"

	// 컨테이너 내부의 인증서를 현재 폴더에 복사 
	docker cp es01:/usr/share/elasticsearch/config/certs/http_ca.crt .

	// https://localhost:9200 포트에 RestFull API 요청 성공, 인증서와  elastic 계정과 패스워드로 요청 성공    
	curl --cacert http_ca.crt -u elastic:$ELASTIC_PASSWORD https://localhost:9200

----------------------------------출력 성공 -----------------------------------------------
{
  "name" : "393df87bb619",
  "cluster_name" : "docker-cluster",
  "cluster_uuid" : "Jp6bXnEET7azYtHB0v41Uw",
  "version" : {
    "number" : "8.13.1",
    "build_flavor" : "default",
    "build_type" : "docker",
    "build_hash" : "9287f29bba5e270bd51d557b8daccb7d118ba247",
    "build_date" : "2024-03-29T10:05:29.787251984Z",
    "build_snapshot" : false,
    "lucene_version" : "9.10.0",
    "minimum_wire_compatibility_version" : "7.17.0",
    "minimum_index_compatibility_version" : "7.0.0"
  },
  "tagline" : "You Know, for Search"
}
-------------------------------------------------------------------------------------------------------

        // 키바나(Kibana ) 설치 : 192.168.15.50:5601     <=== 키바나 관리자 접속 , 원격에서 바로 접속     

	docker pull docker.elastic.co/kibana/kibana:8.13.1
	docker run --name kibana --net elastic -p 5601:5601 docker.elastic.co/kibana/kibana:8.13.1

	// 컨테이너의 접속 해서 관리 <== kibana 컨테이너에 접속
	docker ps -a 
	docker exec -it <컨테이너 ID> /bin/bash 	// 컨테이너에 접속 

	exit      				// 컨테이너를 빠져나옴. 

	// 키바나 설정 (windev) 
	http://192.168.15.50:5601


====================================================================================	
# Elastic DSL 기본 구문 익히기 : JSON 데이터를 쿼리 하는 구문
   

GET _search
{
  "query": {
    "match_all": {}
  }
}

# Elastic DSL : JSON 데이터를 쿼리 하는 구문 

# GET : Select 
# POST : Insert 
# PUT  : Update 
# DELETE : Delete 

# _cat : 전체적인 정보를 출력 

GET _cat
# 샤드 정보 출력 
GET _cat/shards
# Index 정보를 출력 
GET _cat/indices

# 용어 정리 
# =================================
#  DBMS          엘라틱 서치 
# ================================= 
#  테이블         인덱스 
#  레코드         도규먼트 
#  컬럼           필드 
#  스키마         매핑 
# =================================

# 인덱스 생성/ 확인  / 삭제 
PUT index1 

GET index1 

# index 정보를 출력 한다. 테이블 정보를 출력 
GET _cat/indices

DELETE index1

# 도규먼트 생성 
PUT index2/_doc/1
{
  "name": "홍길동", 
  "age": 30 , 
  "gender": "Man"
}

# 인덱스 정보 확인 
GET index2 

# 도규먼트 생성 
PUT index2/_doc/2
{
  "name" : "이순신", 
  "contry": "kor"
}

PUT index2/_doc/3 
{
  "name" : "강감찬", 
  "age"  : "20", 
  "contry" : "kor"
}

# 도규먼트의 모든 내용 출력 하기 
GET index2/_search

# 샘플 데이터의 내용을 출력해 보기 
GET _cat/indices

# index (테이블의 자료형)  정보를 확인 
GET kibana_sample_data_ecommerce

# index 의 Document 의 값을 확인 
GET kibana_sample_data_ecommerce/_search

GET kibana_sample_data_flights/_search

==============================================================================


KORTECH_20240406



캐글 -   빅데이터 , elastic search 에 필요한 데이터들이 저장, 커뮤니티 사이트 
	csv, json ..... 

	- https://www.kaggle.com/

공공 데이터 포털 
	- 공공데이터포털
        - https://www.data.go.kr/


1. 필요한 데이터 다운 
	https://www.kaggle.com/    
	tmdb_5000_movies.csv    // 1900 ~ 2017년도까지 전세계 영화 정보에 대한 DB , CSV ( , 로 분리된 txt 파일)  

2. 로그스테시를 사용해서 필터링 
	
    - 로그스태시 설치 , ElasticSearch 와 Kibana 가 작동 중인 상태에서 실행 
	-- 로그 스테시는 JDK 1.8 이상에서 작동됨.   // JDK가 실치 되어 있어야 함.
	-- JDK 17 이 설치 되어 있음. 
	--  9600 : 로그 스태시가 사용 하는 포트  

   C:\logstash7\bin>.\logstash.bat -e "input { stdin { } } output { stdout{ } }"

   

3. 키바나를 사용해서 필요한 데이터를 import , ElasticSearch로  CSV 파일을  JSON 으로 Import  : 100MB 미만 
	Override settings ==> Time field ( release_date )   <== 중요 , 인덱스 패턴 (키바나에서 접근) index (엘라스틱 서치의 테이블) 

	index (인덱스) : 		ElasticSearch 에서 사용되는 데이터가 JSON 형식으로 저장된 테이블 
	index patten (인덱스 패턴) : Kivana 에서 사용함. elasticsearch의 index (테이블) 값을 읽어와서 색인 (index) 
		-- 키바나에서는 index 에대한 index patten 이 존재해야 키바나에서 사용가능 하다. 
		-- 생성 : Stack Management => Index pattern
			--log.


4. LogStash 에서 전처리 작업후 ElasticSearch 로 전송 ( tmdb_5000_movies2 ) 
   // tmdb_5000_movies.csv 의 첫번째 레코드는 필드명을 선언한 컬럼====> index 에 도규먼트로 등록 되지 않도록 해야함. 
   // genres 컬럼은 text ==> 배열 형식으로 전처리 

	input     => filter     => output 
        원본파일   => filter (전처리 로직)   ==> output   (elasticsearch) 

    step 1 : C:/example/tmdb_5000_movies.csv      	// 전처리할 원본 파일 저장 
    step 2 : C:\logstash7\config\logstash-dmdb2.conf	// 전처리 작업을 작동 시킬 설정 파일 
	=======================================================
input {
  file {
    path => "C:/example/tmdb_5000_movies.csv"
    start_position => "beginning"
    sincedb_path => "nul"
  }
}

output {
  stdout {}
}
	========================================================
    step 3 : 로그시태시를 설정 파일을 읽어서 실행 
	C:\logstash7>.\bin\logstash.bat -f .\config\logstash-dmdb2.conf

    step 4 : 화면에 C:/example/tmdb_5000_movies.csv 읽어 들여서 출력 

// 로그 스태시 작동시 C:/example/tmdb_5000_movies.csv 읽어서 ===> ElasticSerch 로 전송  
    step 5 : C:\logstash7\config\logstash-dmdb3.conf
========================================================================
input {
  file {
    path => "C:/example/tmdb_5000_movies.csv"
    start_position => "beginning"
    sincedb_path => "nul"
  }
}

output {
  elasticsearch {
    hosts => ["http://localhost:9200"]
    index => "tmdb_5000_movies3"
    #user => "elastic"
    #password => "changeme"
  }
}
=========================================================================
    step 6 : C:\logstash7>.\bin\logstash.bat -f .\config\logstash-dmdb3.conf
    step 7 : 키바나 콘솔에서  확인 ; 
    		GET _cat/indices
		GET tmdb_5000_movies3/_search

// 로그스테시에서 C:/example/tmdb_5000_movies.csv 파일을 읽어서 전처리 작업(filter) 을 후 ElasticSearch 로 전송 tmdb_5000_movies3
    step 8 : C:\logstash7>.\bin\logstash.bat -f .\config\logstash-dmdb4.conf
======================================================================
input {
  file {
    path => "C:/example/tmdb_5000_movies.csv"
    start_position => "beginning"
    sincedb_path => "nul"
  }
}


filter {
  csv {
    separator => ","
    columns => ["budget","genres","homepage","id","keywords","original_language",
    "original_title","overview","popularity","production_companies","production_countries",
    "_release_date","revenue","runtime","spoken_languages","status","tagline",
    "title","vote_average","vote_count"]
    remove_field => ["message", "production_companies", "production_countries",
    "keywords", "spoken_languages", "@timestamp", "path", "@version", "host"]
    skip_header => true
  }
 date {
    match => ["_release_date", "YYYY-MM-dd"]
    target => "release_date"
    timezone => "UTC"
    remove_field => "_release_date"
  }

}

output {
  elasticsearch {
    hosts => ["http://localhost:9200"]
    index => "tmdb_5000_movies4"
    #user => "elastic"
    #password => "changeme"
  }
}
======================================================================
    step 9 : C:\logstash7>.\bin\logstash.bat -f .\config\logstash-dmdb4.conf
    step 10 : 키바나 콘솔에서  확인 ; 
    		GET _cat/indices				// tmdb_5000_movies4 출력
		GET tmdb_5000_movies4/_search		// 4700개 값을 출력
		GET tmdb_5000_movies4			// 컬럼의 자료형(스키마, 매핑) 을 확인 


// index 템프릿을 적용해서 매핑 함 , 
    step 11 : https://github.com/himedia20231114/Elastic-Stack/blob/main/TMDB_5000_Movies_Script/06/template_tmdb
	-- kibana console 에서 실행 
===========================================================
PUT _index_template/tmdb
{
  "index_patterns": "tmdb_5000_movie*",
  "priority": 1,
  "template": {
    "mappings": {
        "properties": {
        "budget": { "type": "double" },
        "popularity" : { "type": "double" },
        "vote_average" : { "type": "double" },
        "vote_count" : { "type": "double" },
        "id" : { "type": "long" },
        "revenue" : { "type": "long" },
        "runtime" : { "type": "long" },
        "genres" : { "type": "keyword" },
        "original_language" : { "type": "keyword" },
        "status" : { "type": "keyword" },
        "homepage" : { "type": "text" },
        "original_title" : { "type": "text" },
        "overview" : { "type": "text" },
        "tagline" : { "type": "text" },
        "title" : { "type": "text" },
        "release_date" : { "type": "date", "format" : "iso8601" }
      }
    }
  }
}

===========================================================


    step 12 : C:\logstash7\config\logstash-dmdb5.conf
==================================================================
input {
  file {
    path => "C:/example/tmdb_5000_movies.csv"
    start_position => "beginning"
    sincedb_path => "nul"
  }
}


filter {
  csv {
    separator => ","
    columns => ["budget","genres","homepage","id","keywords","original_language",
    "original_title","overview","popularity","production_companies","production_countries",
    "_release_date","revenue","runtime","spoken_languages","status","tagline",
    "title","vote_average","vote_count"]
    remove_field => ["message", "production_companies", "production_countries",
    "keywords", "spoken_languages", "@timestamp", "path", "@version", "host"]
    skip_header => true
  }
 date {
    match => ["_release_date", "YYYY-MM-dd"]
    target => "release_date"
    timezone => "UTC"
    remove_field => "_release_date"
  }

}

output {
  elasticsearch {
    hosts => ["http://localhost:9200"]
    index => "tmdb_5000_movies5"
    #user => "elastic"
    #password => "changeme"
  }
}


==================================================================
    step 13 : C:\logstash7>.\bin\logstash.bat -f .\config\logstash-dmdb5.conf



++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
1. ElasticSearch 가 실행 
	C:\elasticsearch7\bin>.\elasticsearch.bat

2. Kibana 실행 
	C:\kibana7>.\bin\kibana.bat
	브라우져에서 실행 : http://localhost:5601

3. logstach 실행

C:\logstash7\config\logstash-dmdb6.conf
============================================================
input {
  file {
    path => "C:/example/tmdb_5000_movies.csv"
    start_position => "beginning"
    sincedb_path => "nul"
  }
}


filter {
  csv {
    separator => ","
    columns => ["budget","genres","homepage","id","keywords","original_language",
    "original_title","overview","popularity","production_companies","production_countries",
    "_release_date","revenue","runtime","spoken_languages","status","tagline",
    "title","vote_average","vote_count"]
    remove_field => ["message", "production_companies", "production_countries",
    "keywords", "spoken_languages", "@timestamp", "path", "@version", "host"]
    skip_header => true
  }
 date {
    match => ["_release_date", "YYYY-MM-dd"]
    target => "release_date"
    timezone => "UTC"
    remove_field => "_release_date"
  }

}

output {
  elasticsearch {
    hosts => ["http://localhost:9200"]
    index => "tmdb_5000_movies6"
    #user => "elastic"
    #password => "changeme"
  }
}
============================================================


C:\logstash7>.\bin\logstash.bat -f .\config\logstash-dmdb6.conf 

  // 키바나 콘솔에서 index 가 잘 저장 되었는지 확인 
======================================================
#  index 정보를 출력 

GET _cat/indices

# 스키마 (매핑) : 각 컬럼의 자료형 
GET tmdb_5000_movies6

# index (테이블) 의 값을 출력 
GET tmdb_5000_movies6/_search
=======================================================

키바나에서 Index pattern 생성    <=== 키바나에서 사용 
   index 	: ElasticSearch 에서 index (테이블,값) 
	tmdb_5000_movies6
   index pattern   : Kabana 에서 index 에 대한 Index Pattern ,    <== index (테이블) 의 색인 (index) 
	- 생성 : Stack Management => Index patterns => Create index pattern 
		주의 : Time Field 를 반드시 지정, date 타입이 있는 필드 
		


 
4. filebeat  실행 
+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++


5. 키바나 Discover 를 사용해서 필요한 정보을 필터 해서 읽어옮 

6. 키바나의 Visualize를 사용해서 그래프로 시작화 <== 패턴 
    // 지난 10년동안 어떤 영화 장르가 많이 생성되었는지 ? 
	a

    // 할리우드 영화 중에 평점이 높은 영화는 어느정도 수익이 났는지 ? 
	막대 그래프 



7. 키바나의 Dashboards를 해서 시각화한 패턴의 묶음. 

	원본파일 (csv, log,...) ===> Logstash (전처리, JSON ) ,  (index Template 생성)==> ElasticSearch (index) ==> Kibana (index pattern) ==> 
		Kibana Visualize (시각화) , 패턴  ==> Kibana Dashboards


http://himedia.atosoft.kr/jr.asp
   엘라스틱 서치 데이터 시각화 

 














